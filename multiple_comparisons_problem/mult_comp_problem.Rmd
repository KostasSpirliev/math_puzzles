---
title: "Multiple comparisons problem in R"
author: "Kostas Spirliev"
date: "23 06 2020"
output:
  html_document:
      toc: yes
      toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Постановка проблемы

Проблема множественных сравнений в математической статистике является классической и повторяется чуть ли не в каждом профильном учебнике. Кратко ее можно сформулировать следующим образом[^1]:

[^1]: Проблематика была взята из курса "Основы статистики" на Степике: <https://stepik.org/lesson/8085/step/2?unit=1364>

<center> *Если мы проводим множество статистических тестов, то вероятность, что мы найдем статистически значимый результат при условии, что его на самом деле нет, резко повышается* [^2] </center> \n

[^2]: Более серьезное описание проблемы можно найти в Википедии: <https://en.wikipedia.org/wiki/Multiple_comparisons_problem>

В этом отчете я хочу наглядно продемонстрировать данную проблему с помощью симуляций в R. Также в конце я займусь оптимизацией результирующей функции симуляции.

### Симуляции

Допустим, у нас есть генеральная совокупность со средним $\mu=0$ и $\sigma=1$, и мы 1000 раз берем из этой совокупности по 2 случайные выборки размером 30 наблюдений и сравниваем их среднее с помощью теста Стьюдента. Так как берем мы выборки из одной генеральной совокупности, то мы можем ожидать, что в подавляющем большинстве случаев тест Стьюдента не ошибется и покажет нам, что статистически значимых различий между средними этих выборок нет. При $\alpha=0.05$, из 1000 таких сравнений, мы ошибемся приблизительно 50 раз (т.е. в $\approx5\%$ случаев), что, в принципе, и закладывается в статистике как допустимая вероятность ошибки статистического вывода. Сделаем в R соответствующую симуляцию:

```{r}
set.seed(11)
# Создаем заготовку для наших 2 выборок в виде датафрейма с двумя переменными (значениями двух выборок) и 30 строками (30 наблюдениями для обоих выборок):
d <- data.frame(matrix(0, 2, 30))
# Создаем матрицу попарных сравнений: индексы наших выборок, которые будут сравниваться между собой (в этом случае, таких индексов только 2: первая выборка и вторая)
s <- combn(1:2, 2)
# Создаем заготовку для результатов нашей симуляции: в ней в дальнейшем будут записаны 1 и 0. 0 -- когда значимых различий между выборками нет, и 1 -- когда она есть.
x <- vector("numeric", 1000)

# Теперь производим саму симуляцию с помощью двойного цикла: 1000 раз извлекаем 2 выборки из нашей генеральной совокупности (первый цикл), и внутри каждого цикла перебираем все возможные сравнения выборок с помощью теста Стьюдента (второй цикл). Также проверяем результаты теста Стьюдента: если p.value > 0.05 - то мы признаем, что различия средних между выборками статистически незначимы, если p.value < 0.05, то мы признаем, что эти различия статистически значимы. Если хотя бы одно сравнение произвело статистически значимый результат, то записываем в x -- 1, если нет то 0.
for (q in 1:1000) {
    d <- data.frame(apply(d, 2, function(i) rnorm(30)))
    # Заполняем пустой дата фрейм случайными выборками, 
    # т.е. извлекаем из г.с. m-выборок
    for (i in 1:ncol(s)) {
      TEST <- t.test(d[, s[1, i]], d[, s[2, i]])$p.value
      if(TEST < 0.05) x[q] <- 1
      if(TEST < 0.05) break
    }
  }
```

Визуализируем полученный результат:
```{r warning=FALSE}
library(ggplot2)
ggplot(as.data.frame(x), aes(x = as.factor(x))) +
    geom_histogram(stat = "count", fill = c("blue", "red")) +
    scale_x_discrete(labels = c("Нет", "Да")) +
    xlab("Есть ли значимые различия?") +
    ylab("Количество") +
    ggtitle(paste0("Количество ошибок первого рода ", 
                   sum(x)/length(x)*100, "% ", "(2 выборки)"))

```

В целом, наши ожидания оправдались. В `r sum(x)` случаев из 1000 (т.е. в `r paste0(sum(x)/length(x)*100, "%")`) мы будем ошибаться и признавать, что значимые различия в извлеченных двух выборках есть (хотя мы точно знаем, что их нет, так как они обе были извлечены из одной и той же генеральной совокупности). Теперь напишем функцию общего вида для такого рода симуляции, где на входе мы можем выбрать количество выборок, которые мы будем извлекать 1000 раз из одной генеральной совокупности ($m$), размер каждой выборки ($n$) и порог признания статистически значимых результатов (в прошлый раз $\alpha=0.05$):

```{r}
false_alarm_test <- function(m, n, a) {
  d <- data.frame(matrix(0, n, m))
  s <- combn(1:m, 2)
  x <- vector("numeric", 1000)
  
  for (q in 1:1000) {
    d <- data.frame(apply(d, 2, function(i) rnorm(n)))
    for (i in 1:ncol(s)) {
      TEST <- t.test(d[, s[1, i]], d[, s[2, i]])$p.value
      if(TEST < a) x[q] <- 1
      if(TEST < a) break
    }
  }
ggplot(as.data.frame(x), aes(x = as.factor(x))) +
    geom_histogram(stat = "count", fill = c("blue", "red")) +
    scale_x_discrete(labels = c("Нет", "Да")) +
    xlab("Есть ли значимые различия?") +
    ylab("Количество") +
    ggtitle(paste0("Количество ошибок первого рода ", 
                   sum(x)/length(x)*100, "% ", "(", m, " выбор.)"))
}
```

Протестируем нашу функцию на основе предыдущего примера:
```{r warning=FALSE}
false_alarm_test(2, 30, 0.05)
```

Отлично, получили те же результаты! Теперь можно продемонстрировать саму проблему попарных сравнений. Допустим, теперь мы будем извлекать не 2 выборки, а 3, и сравнивать их между собой на равенство средних с помощью того же теста Стьюдента. Посмотрим, сколько в этот раз мы будем ошибаться:

```{r warning=FALSE}
set.seed(666)
false_alarm_test(3, 30, 0.05)
```

Обратим внимание, что теперь, в каждой из 1000 итераций мы сравниваем **все** три выборки между собой, и если *хотя бы в одном* из сравнений средних p.value теста Стьюдента < 0.05, мы признаем, что обнаружили статистически значимый результат. Теперь таких ложно-положительных результатов в два раза больше -- 11.5%.

Теперь посмотрим на ситуацию с 8 выборками:

```{r warning=FALSE}
set.seed(123)
false_alarm_test(8, 30, 0.05)
```

Теперь мы ошибаемся почти в половине случаев. Попробуем 20 выборок:

```{r warning=FALSE}
false_alarm_test(20, 30, 0.05)
```


Теперь мы ошибаемся почти всегда, что вообще обессмысливает идею проверки статистических гипотез. Для работы над данной проблемой используют специальные поправки Бонферрони/Тьюки, которые сильно снижают $\alpha$ для сокращения количества ложно-положительных результатов. Но мы туда не пойдем -- а скорее сосредоточимся на последнем выполнении функции. Мне она показалась крайне медленной, и на моем компьютере она выполняется порядка 12 секунд(!):

```{r warning=FALSE}
system.time(false_alarm_test(20, 30, 0.05))
```

Займемся оптимизацией этой функции!

### Оптимизация функции симуляции

Посмотрим через *profvis*, что в функции так сильно ее замедляет:
```{r warning=FALSE}
library(profvis)
profvis(false_alarm_test(20, 30, 0.05))
```

Заглянем во вкладку "data". Проблема в функции теста Стьюдента (базовой для R): она съедает практически все время работы процессора. Также совсем немного замедляет все функция data.frame. Мы не будем вдаваться в детали, почему так происходит, а просто, во-первых, заменим data.frame на матрицу (matrix), и, во-вторых, напишем свою, "упрощенную" версию теста Стьюдента, которая принимает на вход два вектора из матрицы, и на выходе отдает исключительно p.value (который как раз нам необходим). Объявим ее прямо в новой "оптимизированной функции":

```{r}
false_alarm_optimized <- function(m, n, a) {
  d <- matrix(0, n, m)
  s <- combn(1:m, 2)
  x <- vector("numeric", 1000)
  
  # Создаем собственную упрощенную версию т.теста, которая возвращает только
  # p.value (должно ускорить всю фунцию)
  t_test_pval <- function(x, y) {
    se <- sqrt((var(x) + var(y))/n)
    t_stat <- (mean(x) - mean(y))/se
    df <- n + n - 2
    pval <- 2*pt(abs(t_stat), df, lower.tail = F)
    pval
  }
  
  for (q in 1:1000) {
    d <- apply(d, 2, function(i) rnorm(n))
    for (i in 1:ncol(s)) {
      TEST <- t_test_pval(d[, s[1, i]], d[, s[2, i]])
      if(TEST < a) x[q] <- 1
      if(TEST < a) break
    }
  }
ggplot(as.data.frame(x), aes(x = as.factor(x))) +
    geom_histogram(stat = "count", fill = c("blue", "red")) +
    scale_x_discrete(labels = c("Нет", "Да")) +
    xlab("Есть ли значимые различия?") +
    ylab("Количество") +
    ggtitle(paste0("Количество ошибок первого рода ", 
                   sum(x)/length(x)*100, "% ", "(", m, " выбор.)"))
}
```

Протестируем результат:

```{r warning=FALSE}
false_alarm_optimized(20, 30, 0.05)
```

Отлично, при 20 выборках получли те же $\approx90\%$ ложноположительных результатов. Посмотрим теперь на скорость работы функции:

```{r warning=FALSE}
system.time(false_alarm_optimized(20, 30, 0.05))
```

Теперь функция на моем компьютере выдает результат за 3 секунды: довольно большой прирост производительности в 4 раза! Возможно, эту функцию можно заоптимизировать еще сильнее, но, к сожалению, пока я еще не настолько хорошо умею программировать :)

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>